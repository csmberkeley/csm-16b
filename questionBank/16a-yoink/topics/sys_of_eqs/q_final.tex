%EE16A - Spring 2018
%Final Exam
%Grace Kuo - gkuo@berkeley.edu

\newpage
\qns{[Out of scope, optional problem] Cactus Care [FINAL QUESTION SP18]}

\meta{
  Feel free to strike/make this problem optional. However, if there are plenty of time left, feel free to help students build the concept of OMP from the basics of 16a!
}

On Midterm 2 you designed a light sensor to check that there is sufficient light in your room for your cactus to be happy and healthy. But you want to monitor the light levels over the course of the day, when you aren't around. You design a transmitter that sends the following periodic code of length $N=5$:
\[ \vec{c} =  \begin{bmatrix}
1 & -3 & 2 & 1 & 2 
\end{bmatrix}^T \]
You encode information about the light by multiplying the code with the light intensity ($y$).
With your cell phone, you receive a shifted version of the code (since it had to travel an unknown distance), multiplied by the light intensity.

\begin{enumerate}

\item
  (4 points) Write a matrix $A$ such that
  \[ A\vec{y} = \vec{r}  \]
  where $\vec{r}$ is the received signal (length 5) and $\vec{y}$ is a vector of all zeros except one entry which contains the light intensity $y$.
  (\textit{Hint: The position of $y$ in the vector $\vec{y}$ will depend on the unknown shift in the signal.})

\ans{
  $A$ is a circulant matrix containing all of the possible shifts of $\vec{c}$ in it's columns:
  \[ A = \begin{bmatrix}
  1 & 2 & 1 & 2 & -3 \\
  -3 & 1 & 2 & 1 & 2 \\
  2 & -3 & 1 & 2 & 1 \\
  1 & 2 & -3 & 1 & 2 \\
  2 & 1 & 2 & -3 & 1
  \end{bmatrix} \]
  You could also write this with the shift notation we used in class, where $\vec{c}^{(k)}$ is $\vec{c}$ circularly shifted by $k$.
  \[ A = \begin{bmatrix}
  \vec{c}^{(0)} & \vec{c}^{(1)} & \vec{c}^{(2)} & \vec{c}^{(3)} & \vec{c}^{(4)}
  \end{bmatrix}
  \]
  
}



\item
  (6 points) This semester your learned several techniques for solving linear systems of equations. For each of the following techniques, could you use it to solve the matrix equation from Part A? Justify your answer in 1-2 sentences. Assume there is no noise.

\textbf{Gaussian Elimination} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
		Explain:

\ans{
	\textbf{Yes.}\\
	 $A$ is a square matrix with linearly independent rows, so we can use Gaussian elimination to solve for $\vec{y}$. 
}

\textbf{Least Squares} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
		Explain:
	
\ans{
	\textbf{Yes.} \\
	Least squares can be used to solve when there are at least as many rows as columns. In this case, where $A$ is square and invertible, the least squares solution is the same as the one you would get with Gaussian elimination. 
}


\textbf{Orthogonal Matching Pursuit} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
		Explain:
	
\ans{
	\textbf{Yes.} \\
	Orthogonal Matching Pursuit can be used for solving for vectors that are mostly zero (sparse vectors). Since $\vec{y}$ contains all zeros except one element, it is sparse and we can use OMP.\\
	Alternative justification: OMP can be used to extract the messages from a small number of beacons sending periodic signals, which is what is happening in this problem.
}
  
%\item
%(5 points) Professor Waller also likes plants, and she suggests that you could recover the light intensity vector $\vec{y}$ from your measurement $\vec{r}$ by calculating the cross-correlation between the code $\vec{c}$ and the received signal $\vec{r}$.
%
%Show that this procedure will work perfectly if the autocorrelation of $\vec{c}$ is 
%\[\begin{bmatrix}
%1 & 0 & 0 & 0 & 0 
%\end{bmatrix}^T \]

%Find a condition on the autocorrelation of $\vec{c}$ such that this procedure works perfectly, in other words, that the cross-correlation of $\vec{r}$ with $\vec{c}$ returns $\vec{y}$ exactly.

%\textbf{Bonus:} Find a $\vec{c}$ with this autocorrelation.

%\inexamnotsol{
%	\makenonemptybox{5in}{}
%	\clearpage
%	}
%	
%\sol{
%
%	
%}

\end{enumerate}
You're not sure that your room is really the right place for your cactus, so you set up another light detector in the lab to see if it's better. Each of the two light detectors has a transmitter with a different periodic code $c_1$, $c_2$. 
\[ \vec{c_1} =  \begin{bmatrix}
1 & -3 & 2 & 1 & 2 
\end{bmatrix}^T \]
\[\vec{c_2} =  \begin{bmatrix}
3 & 1 & 2 & -2 & -1 
\end{bmatrix} ^T \]
As before, the codes are multiplied by the light intensities at each location, $y_1$ and $y_2$, and your cell phone receives the sum of shifted codes, each weighted by the light at that location.

\begin{enumerate}
\setcounter{enumi}{2}
\item
(5 points) Write a new matrix $A$ such that
\[ A \vec{y} = \vec{r} \]
where $\vec{r}$ is the received signal (length 5) and $\vec{y}$ is a vector of all zeros except two entries which contain $y_1$ and $y_2$.\\
 \textit{Hint: The positions of $y_1$ and $y_2$ in the vector $\vec{y}$ will depend on the unknown shifts in $c_1$ and $c_2$, respectively.} 
 

\ans{
	$A$ contains all of the possible shifts of each code in it's columns.
	  \[ A = \begin{bmatrix}
	  1 & 2 & 1 & 2 & -3 & \quad 3 &-1 &-2 &2 &1\\
	  -3 & 1 & 2 & 1 & 2 & \quad 1 &3 &-1 &-2 &2 \\
	  2 & -3 & 1 & 2 & 1 & \quad 2 &1 &3 &-1 &-2 \\
	  1 & 2 & -3 & 1 & 2 & \quad -2 &2 &1 &3 &-1 \\
	  2 & 1 & 2 & -3 & 1 & \quad -1 &-2 &2 &1 &3
	  \end{bmatrix} \]
	  You could also write this with the shift notation we used in class, where $\vec{c}^{(k)}$ is $\vec{c}$ circularly shifted by $k$.
	  \[ A = \begin{bmatrix}
	  \vec{c}_1^{(0)} & \vec{c}_1^{(1)} & \vec{c}_1^{(2)} & \vec{c}_1^{(3)} & \vec{c}_1^{(4)} & \vec{c}_2^{(0)} & \vec{c}_2^{(1)} & \vec{c}_2^{(2)} & \vec{c}_2^{(3)} & \vec{c}_2^{(4)}
	  \end{bmatrix}
	  \]
	
	}

\item
(6 points) For each of the following techniques, could you use it to solve the matrix equation from Part D, with two different light sensors? Justify your answer in 1-2 sentences. Assume there is no noise.

	

\textbf{Gaussian Elimination} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
			Explain:

\ans{
	\textbf{No.} \\
	There are more columns than rows in $A$ so if we attempt Gaussian Elimination, there will not be a pivot in every column. This means there are infinitely many possible solutions.
}

\textbf{Least Squares} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
			Explain:
	
\ans{
	\textbf{No.} \\
	Least squares can only be used to solve a system of equations when there are at least as many rows as columns. In this case there are fewer rows than columns, so we cannot use least squares.\\
	\\
	To see this, let's look at the least squares equation:
	\[\hat{\vec{y}} = (A^TA)^{-1} A^T\vec{r} \]
	If $A$ has more columns than rows, $A^TA$ cannot be full rank, so it is not invertible.
	
	\textbf{Common Mistakes:}
	\begin{itemize}
		\item Many students said that least squares only works for OVER-determined systems, however that's not true because it works for perfectly determined systems as well.
	\end{itemize}
}


\textbf{Orthogonal Matching Pursuit} \quad $\bigcirc$ yes \quad $\bigcirc$ no \\
			Explain:

\ans{
	\textbf{Yes.} \\
	Orthogonal Matching Pursuit can be used for solving for vectors that are mostly zeros, even when the system of equations is underdetermined. Since $\vec{y}$ contains all zeros except two elements, it is sparse and we can use OMP.
	Alternative justification: OMP can be used to extract the messages from a small number of beacons sending periodic signals, which is what is happening in this problem.
	
}
	

	\item
	(3 points) In order to judge if your codes are ``good'', you want to calculate the autocorrelations and cross-correlation of your codes. Professor Waller helps you calculate the following:
	
			\[\text{autocorrelation of } \vec{c_1} =  \begin{bmatrix}
			19 & -3 & \textbf{??} & -2 & -3
			\end{bmatrix} ^T \]
			\[\text{autocorrelation of } \vec{c_2} =  \begin{bmatrix}
			19 & 0 & -5 & -5 & 0
			\end{bmatrix} ^T \]
			\[\text{cross-correlaton of } \vec{c_1} \text{ with } \vec{c_2} = \begin{bmatrix}
			0 & -10 & 12 & 11 & -4
			\end{bmatrix} ^T \]
			
	Finish the set by calculating the unknown term in the autocorrelation of $c_1$.

	

	\ans{
		
	The missing term of the autocorrelation is the inner product of the code with a version of itself, circularly shifted by 2.
	
	\[ \vec{c_1} =  \begin{bmatrix}
	1 & -3 & 2 & 1 & 2 
	\end{bmatrix}^T \]
	
	\begin{align*}
%	\text{autocorr. at lag 0 }= (1)(1) + (-3)(-3) + (2)(2) + (1)(1) + (2)(2)=& 19  \\
%	\text{autocorr. at lag 1 }= (1)(-3) + (-3)(2) + (2)(1) + (1)(2) + (2)(1) =& -3 \\ 
	\text{autocorr. at lag 2 }= (1)(2) + (-3)(1) + (2)(2) + (1)(1) + (2)(-3) =& -2 \\ 
%	\text{autocorr. at lag 3 }= (1)(1) + (-3)(2) + (2)(1) + (1)(-3) + (2)(2) =& -2 \\ 
%	\text{autocorr. at lag 2 }= (1)(2) + (-3)(1) + (2)(-3) + (1)(2) + (2)(1) =& -3 \\ 
	\end{align*}
	
		
		}

	\item
	(6 points) Consider the following set of codes ($c_3$ and $c_4$). 
	\[ \vec{c_3} =  \begin{bmatrix}
				1 & -2 & -3 & 2 & 1 
			\end{bmatrix}^T  \hspace{1in}
			\vec{c_4} =  \begin{bmatrix}
				1 & 1 & 2 & -2 & -3
			\end{bmatrix} ^T  \]
	\[ \text{autocorr. of } \vec{c_3} =  \begin{bmatrix}
			19 & 1 & -10 & -10 & 1
			\end{bmatrix} ^T\]
	\[ \text{autocorr. of } \vec{c_4} =  \begin{bmatrix}
			19 & 2 & -11 & -11 & 2
			\end{bmatrix} ^T\]	
	\[ \text{cross-correlation of } \vec{c_3} \text{ with } \vec{c_4} =  \begin{bmatrix}
		-14 & -16 & 5 & 18 & -2
		\end{bmatrix} ^T\]
		
%	\begin{center}
%	\begin{tabular}{l l}
%		$\vec{c_3} =  \begin{bmatrix}
%			1 & -2 & -3 & 2 & 1 
%		\end{bmatrix}^T $ &
%		$\vec{c_4} =  \begin{bmatrix}
%			1 & 1 & 2 & -2 & -3
%		\end{bmatrix} ^T $ \\
%		$ \text{autocorr. of } \vec{c_3} =  \begin{bmatrix}
%		19 & 1 & -10 & -10 & 1
%		\end{bmatrix} ^T $ &
%		$ \text{autocorr. of } \vec{c_4} =  \begin{bmatrix}
%		19 & 2 & -11 & -11 & 2
%		\end{bmatrix} ^T $ \\
%		
%	\end{tabular}
%	$\text{cross-correlation of } \vec{c_3} \text{ with } \vec{c_4} =  \begin{bmatrix}
%	-14 & -16 & 5 & 18 & -2
%	\end{bmatrix} ^T$
%	\end{center}
	
	
	If you use OMP to solve for the light intensities, which set of codes ($c_1$,$c_2$ OR $c_3$,$c_4$) is more robust to noise in the received signal? Justify your answer. For the set of codes that is worse, what mistake will is most likely to happen during the OMP algorithm in the presence of noise?
	

			 \begin{center} $\bigcirc$ $c_1,c_2$ are more robust \hspace{1in} $\bigcirc$ $c_3,c_4$ are more robust 
			 \end{center}

	
	\ans{
		\textbf{$\mathbf{c_1}$ and $\mathbf{c_2}$} are more robust to noise. This is because they are ``more orthogonal" than $c_3$ and $c_4$ for all possible shifts, ie. the autocorrelation (at non-zero shift) and cross-correlations of $c_1,c_2$ are generally closer to zero.
		
		Specifically, the cross-correlation of $c_3,c_4$ has a peak of magnitude 18, which is almost as high as the autocorrelation at zero shift. This means that if we try to use OMP with $c_3,c_4$ we are likely to accidentally mistake $c_3$ for $c_4$ at a different shift (or vice versa). \\
		
		\textbf{Common Mistakes:}
		\begin{itemize}
			\item Saying that $c_1$,$c_2$ are more robust because they are orthogonal at time shift zero (first term of the cross-correlation is 0). We need to check that the codes are nearly orthogonal for all time shifts, not just 0. This did not get credit because you could have a pair of codes that are orthogonal at lag 0 but have a very high cross correlation at a different lag. Additional explanation is needed to get credit for your justification.
			\item Saying that $c_1$,$c_2$ are more robust because they have autocorrelations that are more different from each other than those of $c_3$,$c_4$. In OMP we know which code we cross-correlated with the received signal, so we don't need the autocorrelations to be different. We just want a high peak at 0 lag and low every where else.
			\item Thinking that the cross-correlation given is the cross-correlation which is calculated during OMP, in other words, the cross-correlation that we are trying to find peaks in. This is not the case, it is the cross-correlation between the two codes, which does not include information from the received signal.
		\end{itemize}
		
		}
\end{enumerate}


